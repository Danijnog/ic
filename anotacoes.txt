Llama3: fez a sumarização de um grupo bem rápido (por volta de 23s), porém não está muito preciso.

Maritalk: modelo testado: sabia-2-medium: fez a sumarização de um grupo devagar (2m e 20 seg), porém está mais preciso. 
Foi gasto 0,22/0,215 reais para fazer a sumarização dos arquivos de mensagens de um grupo.

Porém, o sabia-2-medium as vezes nos da informações incorretas a respeito da sumarização, por exemplo alucinações do modelo, porém nada demais.

C4AI: é o modelo que melhor se adaptou: superou maritalk e llama3, na minha opinião.
Acho que, de certa forma, ficou até mais organizado que o modelo gpt-3.5-turbo.
Porém: é caro.

Anotações úteis que tirei do código:

OpenAI API Setup
API_KEY = "sk-proj-sK84FwUTPUpgcdvYeTgzT3BlbkFJgFj7H9JNw6tSLwstXuFD"
TEXT_MODEL = "gpt-3.5-turbo"
APIclient = OpenAI(api_key = API_KEY)

Llama 3 Setup
API_KEY_LLAMA3 = "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"
LLAMA3_MODEL = "llama3-8b-8192"
from groq import Groq
APIclient_llama3 = Groq(api_key = API_KEY_LLAMA3)
Cerca de 43h para fazer o sumário de todos os grupos

Maritalk Setup
import maritalk
API_KEY_MARITALK = "114784108350362647579$2fc4910d7c5aab63"

model = maritalk.MariTalk(
    key = API_KEY_MARITALK,
    model = "sabia-2-medium"
)

NVIDIA: tempo para fazer o sumário de um grupo: 2m e 18seg.
Fez uma sumarização coerente dos arquivos, porém o fato é que ele foi treinado em um corpus de texto em inglês:
three different types of data used: English natural language data (70%), multilingual natural language data (15%), and source code data (15%)

A sumarização está bem completa e coerente, não verifiquei nenhuma alucinação em nenhum arquivo.
